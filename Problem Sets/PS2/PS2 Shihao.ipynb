{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697b5b13",
   "metadata": {},
   "source": [
    "# Solutions to Problem Set 2\n",
    "\n",
    "*Stats 507, Fall 2021*\n",
    "\n",
    "Shihao Wu, PhD student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f473776",
   "metadata": {},
   "source": [
    "## Question 0 - Code review warmup\n",
    "\n",
    "Many organizations that produce software utilize code reviews to help mantain a high quality code base. A good code review should address the following questions:\n",
    "\n",
    "1. Does the code work? Does it do what it is supposed to?\n",
    "2. How is the style of the code? Does it follow the style guidelines?\n",
    "3. Is the code clearly structured and easy to understand?\n",
    "4. Is the code efficient? If clarity is sacrificed for efficiency, are there comments that help to alleviate this?\n",
    "\n",
    "In this question, you will interpret a code snippet you did not write and then write a “code review” for that snippet.\n",
    "### Code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234b6beb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-537e3dd702ce>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-537e3dd702ce>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for n in range(len(sample_list)):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][0] == sample_list[n][0] and\n",
    "                    sample_list[m][3] != sample_list[n][3]):\n",
    "                li.append(sample_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[3], reverse=True)[0])\n",
    "res = list(set(op))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47dd26",
   "metadata": {},
   "source": [
    "### Code review\n",
    "\n",
    "**a.** Given a list of tuples, the codes aim to find the tuples with unique first numbers, and the tuples are uniquely picked if it has the largest third number among all all tuples that has the same first number as it. There are a few suggestions for the code writer.  \n",
    "\n",
    "**b.** The codes do not work currently due to 'unexpected indent' and 'tuple index out of range' errors. To revise that, the writer should use consistent indentation (preferably with 4 spaces for each level of indentation) throught the code and be careful about *where to have indentation*. Index in python for a length-$p$ list/tuple **a** starts from $0$ and ends at $p$-1. Using **a**\\[p\\] will return 'out of index' error. If one wants to get the $p$th item in **a**, use **a**\\[p-1\\]. When iterating within the sample list, the writer iterated indices. Instead, the writer should try iterating over values in the list, which is more efficient and simple. The code is well structured and not too difficult to understand the intention. However, when using the <code>lambda</code> function in Python, it would be better to add comments to make it more understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9a973",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The remaining questions will use the following imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53a7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules: --------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "# --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90803b",
   "metadata": {},
   "source": [
    "## Question 1 - List of Tuples\n",
    "\n",
    "Write a function that uses NumPy and a list comprehension to \n",
    "generate a random list of <code>n</code> k-tuples containing integers \n",
    "ranging from <code>low</code> to high. Choose an appropriate name \n",
    "for your function, and reasonable default values for k, <code>l\n",
    "ow</code>, and <code>high</code>.\n",
    "\n",
    "Use <code>assert</code> to test that your function returns a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0649f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lt(n, k=1, low=0, high=100):\n",
    "    \"\"\"\n",
    "    Generate a random list of tuples.\n",
    "\n",
    "    generate a random list of n k-tuples containing integers ranging\n",
    "    from low to high.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The length of list.\n",
    "    k : int\n",
    "        The length of each tuple within the list.\n",
    "    low, high : int\n",
    "        Values of the range of the random integers generated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The final list 'gen_list' .\n",
    "\n",
    "    \"\"\"\n",
    "    gen_list = [tuple(np.random.randint(low=low, high=high, size=k)) \n",
    "                for i in range(n)]\n",
    "    return gen_list\n",
    "\n",
    "assert [type(i) == tuple for i in gen_lt(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb8929",
   "metadata": {},
   "source": [
    "## Question 2 - Refactor the Snippet\n",
    "\n",
    "In this question, you will write functions to accomplish the \n",
    "goal you concisely described in part “a” of the warm up.\n",
    "\n",
    "a. Encapsulate the code snippet from the warmup into a function \n",
    "that parameterizes the role of <code>0</code> and <code>3</code> and is otherwise \n",
    "unchanged. Choose appropriate names for these paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecd140e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2), (1, 9, 8)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def res(in_list, uni_idx, com_idx):\n",
    "    \"\"\"\n",
    "    Refine a list of tuples with fewer tuples.\n",
    "\n",
    "    Find the tuples with unique 'uni_idx'th numbers, and the tuples\n",
    "    are uniquely picked if it has the largest 'com_idx'th number among \n",
    "    all all tuples that has the same 'uni_idx'th number as it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list : list of tuples\n",
    "        The list waiting for the refinement.\n",
    "    uni_idx : int\n",
    "        The index of the number in the tuples that we want it to be unique.\n",
    "    com_idx : int\n",
    "        The index of the number in the tuples to compare for selecting\n",
    "        the tuple that has the largest 'com_idx's number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The final list 'res' .\n",
    "\n",
    "    \"\"\"\n",
    "    op = []\n",
    "    for m in range(len(in_list)):\n",
    "        li = [in_list[m]]\n",
    "        for n in range(len(in_list)):\n",
    "            if (in_list[m][uni_idx] == in_list[n][uni_idx] and\n",
    "                    in_list[m][com_idx] != in_list[n][com_idx]):\n",
    "                li.append(in_list[n])\n",
    "        op.append(sorted(li, key=lambda dd: dd[com_idx], reverse=True)[0])\n",
    "    res = list(set(op))\n",
    "    return res\n",
    "\n",
    "res([(1, 3, 5), (0, 1, 2), (1, 9, 8)],0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9dde8d",
   "metadata": {},
   "source": [
    "b. Write an improved version of the function from part a that\n",
    "implements the suggestions from the code review you wrote\n",
    "in part b of the warmup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "130a0ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2), (1, 9, 8)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def res_imp(in_list, uni_idx, com_idx):\n",
    "    \"\"\"\n",
    "    Improved version of res(in_list, uni_idx, com_idx).\n",
    "    Refine a list of tuples with fewer tuples.\n",
    "\n",
    "    Find the tuples with unique 'uni_idx'th numbers, and the tuples\n",
    "    are uniquely picked if it has the largest 'com_idx'th number among \n",
    "    all tuples that has the same 'uni_idx'th number as it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list : list of tuples\n",
    "        The list waiting for the refinement.\n",
    "    uni_idx : int\n",
    "        The index of the number in the tuples that we want it to be unique.\n",
    "    com_idx : int\n",
    "        The index of the number in the tuples to compare for selecting\n",
    "        the tuple that has the largest 'com_idx's number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The final list 'res' .\n",
    "\n",
    "    \"\"\"\n",
    "    op = []\n",
    "    for tup1 in in_list:\n",
    "        li = [tup1]\n",
    "        for tup2 in in_list:\n",
    "            if (tup1[uni_idx] == tup2[uni_idx] and\n",
    "                    tup1[com_idx] != tup2[com_idx]):\n",
    "                li.append(tup2)\n",
    "        \n",
    "        # Find the tuple that has the largest 'com_idx's number among \n",
    "        # all tuples that has the same 'uni_idx'th number as it.\n",
    "        op.append(sorted(li, key=lambda dd: dd[com_idx], reverse=True)[0])\n",
    "    res_imp = list(set(op))\n",
    "    return res_imp\n",
    "\n",
    "res_imp([(1, 3, 5), (0, 1, 2), (1, 9, 8)],0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c67fb6",
   "metadata": {},
   "source": [
    "c. Write a function from scratch to accomplish the same task \n",
    "as the previous two parts. Your solution should traverse\n",
    "the input list of tuples no more than twice. Hint: consider \n",
    "    using a dictionary or a default dictionary in your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd50c34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2), (1, 9, 8)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def res_dic(in_list, uni_idx, com_idx, dic=None):\n",
    "    \"\"\"\n",
    "    Improved version of res_imp(in_list, uni_idx, com_idx) with \n",
    "    traversing the input list of tuples no more than twice (using\n",
    "    a dictionary).\n",
    "    Refine a list of tuples with fewer tuples.\n",
    "\n",
    "    Find the tuples with unique 'uni_idx'th numbers, and the tuples\n",
    "    are uniquely picked if it has the largest 'com_idx'th number among \n",
    "    all tuples that has the same 'uni_idx'th number as it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_list : list of tuples\n",
    "        The list waiting for the refinement.\n",
    "    uni_idx : int\n",
    "        The index of the number in the tuples that we want it to be unique.\n",
    "    com_idx : int\n",
    "        The index of the number in the tuples to compare for selecting\n",
    "        the tuple that has the largest 'com_idx's number.\n",
    "    dic : dictionary\n",
    "        The dictionary that groups all the tuples by their 'uni_idx' \n",
    "        number. Can be optional as input or find within the function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The final list 'res_dic' .\n",
    "\n",
    "    \"\"\"\n",
    "    if dic == None:\n",
    "        dic = {}\n",
    "        for li in in_list:\n",
    "            uni_num = str(li[uni_idx])\n",
    "            if uni_num not in dic.keys():\n",
    "                dic[uni_num] = [li]\n",
    "            else:\n",
    "                dic[uni_num].append(li)\n",
    "    op = []\n",
    "    for key_val in dic.keys():\n",
    "        op.append(sorted(dic[key_val], key=lambda dd: dd[com_idx], reverse=True)[0])\n",
    "    res_dic = list(set(op))\n",
    "    return res_dic\n",
    "\n",
    "res_dic([(1, 3, 5), (0, 1, 2), (1, 9, 8)],0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d50fd",
   "metadata": {},
   "source": [
    "d. Using the function you wrote in question 1 to generate a list \n",
    "of tuples as input(s), run and summarize a small Monte Carlo \n",
    "study comparing the execution times of the three functions \n",
    "above (a-c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b534a06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n</th>\n",
       "      <th>res() time</th>\n",
       "      <th>res_imp() time</th>\n",
       "      <th>res_dic() time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0:00:00.000057</td>\n",
       "      <td>0:00:00.000036</td>\n",
       "      <td>0:00:00.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0:00:00.000222</td>\n",
       "      <td>0:00:00.000149</td>\n",
       "      <td>0:00:00.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0:00:00.001370</td>\n",
       "      <td>0:00:00.000906</td>\n",
       "      <td>0:00:00.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0:00:00.008627</td>\n",
       "      <td>0:00:00.005689</td>\n",
       "      <td>0:00:00.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0:00:00.100651</td>\n",
       "      <td>0:00:00.062807</td>\n",
       "      <td>0:00:00.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0:00:00.914204</td>\n",
       "      <td>0:00:00.564544</td>\n",
       "      <td>0:00:00.002309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0:00:56.733748</td>\n",
       "      <td>0:00:06.335263</td>\n",
       "      <td>0:00:00.008054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0:01:34.931884</td>\n",
       "      <td>0:01:00.207007</td>\n",
       "      <td>0:00:00.026140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_choices = [10, 30, 100, 300, 1000, 3000, 10000,30000]\n",
    "time_res = []\n",
    "time_imp = []\n",
    "time_dic = []\n",
    "\n",
    "for n in n_choices:\n",
    "    time_imp_int = []\n",
    "    time_dic_int = []\n",
    "    time_res_int = []\n",
    "    for i in range(10): # 10-time Monte Carlo repetitions\n",
    "        list_t = gen_lt(n=n, k=10, low=0, high=100)\n",
    "        start = datetime.datetime.now()\n",
    "        res(in_list=list_t, uni_idx=1, com_idx=3)\n",
    "        time_res_int.append(datetime.datetime.now() - start)\n",
    "        list_t = gen_lt(n=n, k=10, low=0, high=100)\n",
    "        start = datetime.datetime.now()\n",
    "        res_imp(in_list=list_t, uni_idx=1, com_idx=3)\n",
    "        time_imp_int.append(datetime.datetime.now() - start)\n",
    "        list_t = gen_lt(n=n, k=10, low=0, high=100)\n",
    "        start = datetime.datetime.now()\n",
    "        res_dic(in_list=list_t, uni_idx=1, com_idx=3)\n",
    "        time_dic_int.append(datetime.datetime.now()-start)\n",
    "    time_res.append(str(np.mean(time_res_int)))\n",
    "    time_imp.append(str(np.mean(time_imp_int)))\n",
    "    time_dic.append(str(np.mean(time_dic_int)))\n",
    "\n",
    "\n",
    "    \n",
    "tab = pd.DataFrame(\n",
    "    {\n",
    "     \"n\": n_choices,\n",
    "     \"res() time\" : time_res,\n",
    "     \"res_imp() time\" : time_imp,\n",
    "     \"res_dic() time\" : time_dic,\n",
    "     }\n",
    "    )\n",
    "\n",
    "\n",
    "display(HTML(tab.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5968471",
   "metadata": {},
   "source": [
    "## Question 3 \n",
    "\n",
    "In this question you will use Pandas to read, clean, and append several data files from the National Health and Nutrition Examination Survey NHANES. We will use the data you prepare in this question as the starting point for analyses in one or more future problem sets. For this problem, you should use the four cohorts spanning the years 2011-2018. \n",
    "\n",
    "a. Use Python and Pandas to read and append the demographic datasets keeping only columns containing the unique ids (SEQN), age (RIDAGEYR), race and ethnicity (RIDRETH3), education (DMDEDUC2), and marital status (DMDMARTL), along with the following variables related to the survey weighting: (RIDSTATR, SDMVPSU, SDMVSTRA, WTMEC2YR, WTINT2YR). Add an additional column identifying to which cohort each case belongs. Rename the columns with literate variable names using all lower case and convert each column to an appropriate type. Finally, save the resulting data frame to a serialized “round-trip” format of your choosing (e.g. pickle, feather, or parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6bd406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              string\n",
      "age            float64\n",
      "race            string\n",
      "education       string\n",
      "marital         string\n",
      "examination     string\n",
      "pseudo-sup     float64\n",
      "pseudo-stra    float64\n",
      "mec             string\n",
      "interviewed     string\n",
      "cohort          object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>examination</th>\n",
       "      <th>pseudo-sup</th>\n",
       "      <th>pseudo-stra</th>\n",
       "      <th>mec</th>\n",
       "      <th>interviewed</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62161</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>104236.582554</td>\n",
       "      <td>102641.406474</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62162</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>16116.35401</td>\n",
       "      <td>15457.736897</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62163</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7869.485117</td>\n",
       "      <td>7397.684828</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62164</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>127965.226204</td>\n",
       "      <td>127351.373299</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62165</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>13384.042162</td>\n",
       "      <td>12209.74498</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39152</th>\n",
       "      <td>102952</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18338.711104024176</td>\n",
       "      <td>16896.27620310902</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39153</th>\n",
       "      <td>102953</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>63661.95157344447</td>\n",
       "      <td>61630.3800130472</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39154</th>\n",
       "      <td>102954</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>17694.78334581792</td>\n",
       "      <td>17160.895268622276</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39155</th>\n",
       "      <td>102955</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>14871.83963566592</td>\n",
       "      <td>14238.445922281095</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39156</th>\n",
       "      <td>102956</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>39426.29994756593</td>\n",
       "      <td>38645.740290861075</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39156 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   age race education marital examination  pseudo-sup  \\\n",
       "1       62161  22.0  3.0       3.0     5.0         2.0         1.0   \n",
       "2       62162   3.0  1.0      <NA>    <NA>         2.0         3.0   \n",
       "3       62163  14.0  6.0      <NA>    <NA>         2.0         3.0   \n",
       "4       62164  44.0  3.0       4.0     1.0         2.0         1.0   \n",
       "5       62165  14.0  4.0      <NA>    <NA>         2.0         2.0   \n",
       "...       ...   ...  ...       ...     ...         ...         ...   \n",
       "39152  102952  70.0  6.0       3.0     1.0         2.0         2.0   \n",
       "39153  102953  42.0  1.0       3.0     4.0         2.0         2.0   \n",
       "39154  102954  41.0  4.0       5.0     5.0         2.0         1.0   \n",
       "39155  102955  14.0  4.0      <NA>    <NA>         2.0         1.0   \n",
       "39156  102956  38.0  3.0       4.0     3.0         2.0         1.0   \n",
       "\n",
       "       pseudo-stra                 mec         interviewed     cohort  \n",
       "1             91.0       104236.582554       102641.406474  2011-2012  \n",
       "2             92.0         16116.35401        15457.736897  2011-2012  \n",
       "3             90.0         7869.485117         7397.684828  2011-2012  \n",
       "4             94.0       127965.226204       127351.373299  2011-2012  \n",
       "5             90.0        13384.042162         12209.74498  2011-2012  \n",
       "...            ...                 ...                 ...        ...  \n",
       "39152        138.0  18338.711104024176   16896.27620310902  2017-2018  \n",
       "39153        137.0   63661.95157344447    61630.3800130472  2017-2018  \n",
       "39154        144.0   17694.78334581792  17160.895268622276  2017-2018  \n",
       "39155        136.0   14871.83963566592  14238.445922281095  2017-2018  \n",
       "39156        142.0   39426.29994756593  38645.740290861075  2017-2018  \n",
       "\n",
       "[39156 rows x 11 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I spend a lot of lines to make the indexes in the final data frame \n",
    "# right.\n",
    "\n",
    "df1 = pd.read_sas('DEMO_G.XPT')\n",
    "df1 = df1[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL',\n",
    "          'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "n_df1 = df1.shape[0]\n",
    "df1['cohort of the case'] = ['2011-2012'] * n_df1\n",
    "\n",
    "dic_df1 = {}\n",
    "for name in df1.columns:\n",
    "    dic_df1[name] = list(df1[name])\n",
    "df1_frame = pd.DataFrame(\n",
    "    dic_df1, index = list(range(1, n_df1+1))\n",
    ")\n",
    "\n",
    "\n",
    "df2 = pd.read_sas('DEMO_H.XPT')\n",
    "df2 = df2[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL',\n",
    "          'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "n_df2 = df2.shape[0]\n",
    "df2['cohort of the case'] = ['2013-2014'] * n_df2\n",
    "\n",
    "dic_df2 = {}\n",
    "for name in df2.columns:\n",
    "    dic_df2[name] = list(df2[name])\n",
    "df2_frame = pd.DataFrame(\n",
    "    dic_df2, index = list(range(n_df1 + 1, n_df1 + n_df2 + 1))\n",
    ")\n",
    "\n",
    "df3 = pd.read_sas('DEMO_I.XPT')\n",
    "df3 = df3[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL',\n",
    "          'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "n_df3 = df3.shape[0]\n",
    "df3['cohort of the case'] = ['2015-2016'] * n_df3\n",
    "\n",
    "dic_df3 = {}\n",
    "for name in df3.columns:\n",
    "    dic_df3[name] = list(df3[name])\n",
    "df3_frame = pd.DataFrame(\n",
    "    dic_df3, index = list(range(n_df1 + n_df2 + 1, n_df1 + n_df2 + \n",
    "                                n_df3 + 1))\n",
    ")\n",
    "\n",
    "df4 = pd.read_sas('DEMO_J.XPT')\n",
    "df4 = df4[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL',\n",
    "          'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "n_df4 = df4.shape[0]\n",
    "df4['cohort of the case'] = ['2017-2018'] * n_df4\n",
    "\n",
    "dic_df4 = {}\n",
    "for name in df4.columns:\n",
    "    dic_df4[name] = list(df4[name])\n",
    "df4_frame = pd.DataFrame(\n",
    "    dic_df4, index = list(range(n_df1 + n_df2 + n_df3 + 1, n_df1 + \n",
    "                                n_df2 + n_df3 + n_df4 + 1))\n",
    ")\n",
    "\n",
    "\n",
    "df_demo = pd.concat([df1_frame, df2_frame, df3_frame, df4_frame])\n",
    "df_demo = df_demo.set_axis([\"id\", \"age\", \"race\" , \n",
    "                            \"education\", \"marital\", \n",
    "                            \"examination\",\n",
    "                            \"pseudo-sup\",\n",
    "                            \"pseudo-stra\",\n",
    "                            \"mec\",\n",
    "                            \"interviewed\", \"cohort\"], axis=1)\n",
    "df_demo = df_demo.astype({'id': 'int64'})\n",
    "df_demo = df_demo.astype({'id': 'string'})\n",
    "df_demo = df_demo.astype({'race': 'string'})\n",
    "df_demo = df_demo.astype({'education': 'string'})\n",
    "df_demo = df_demo.astype({'marital': 'string'})\n",
    "df_demo = df_demo.astype({'examination': 'string'})\n",
    "df_demo = df_demo.astype({'mec': 'string'})\n",
    "df_demo = df_demo.astype({'interviewed': 'string'})\n",
    "\n",
    "\n",
    "print(df_demo.dtypes)\n",
    "df_demo.to_pickle('df_demo.pickle')\n",
    "df_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1cd34e",
   "metadata": {},
   "source": [
    "b. Repeat part a for the oral health and dentition data (OHXDEN_*.XPT) retaining the following variables: SEQN, OHDDESTS, tooth counts (OHXxxTC), and coronal cavities (OHXxxCTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5771e15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          float64\n",
      "OHDDESTS    float64\n",
      "OHX01TC     float64\n",
      "OHX02TC     float64\n",
      "OHX02CTC     object\n",
      "             ...   \n",
      "OHX30TC     float64\n",
      "OHX30CTC     object\n",
      "OHX31TC     float64\n",
      "OHX31CTC     object\n",
      "cohort       object\n",
      "Length: 62, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>OHDDESTS</th>\n",
       "      <th>OHX01TC</th>\n",
       "      <th>OHX02TC</th>\n",
       "      <th>OHX02CTC</th>\n",
       "      <th>OHX03TC</th>\n",
       "      <th>OHX03CTC</th>\n",
       "      <th>OHX04TC</th>\n",
       "      <th>OHX04CTC</th>\n",
       "      <th>OHX05TC</th>\n",
       "      <th>...</th>\n",
       "      <th>OHX27CTC</th>\n",
       "      <th>OHX28TC</th>\n",
       "      <th>OHX28CTC</th>\n",
       "      <th>OHX29TC</th>\n",
       "      <th>OHX29CTC</th>\n",
       "      <th>OHX30TC</th>\n",
       "      <th>OHX30CTC</th>\n",
       "      <th>OHX31TC</th>\n",
       "      <th>OHX31CTC</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62165.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35905</th>\n",
       "      <td>102952.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35906</th>\n",
       "      <td>102953.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35907</th>\n",
       "      <td>102954.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'F'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35908</th>\n",
       "      <td>102955.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35909</th>\n",
       "      <td>102956.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'E'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>b'E'</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35909 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  OHDDESTS  OHX01TC  OHX02TC OHX02CTC  OHX03TC OHX03CTC  \\\n",
       "1       62161.0       1.0      4.0      2.0     b'S'      2.0     b'S'   \n",
       "2       62162.0       1.0      4.0      4.0     b'U'      4.0     b'U'   \n",
       "3       62163.0       1.0      4.0      2.0     b'S'      2.0     b'Y'   \n",
       "4       62164.0       1.0      4.0      2.0     b'Z'      2.0     b'Z'   \n",
       "5       62165.0       1.0      4.0      2.0     b'S'      2.0     b'S'   \n",
       "...         ...       ...      ...      ...      ...      ...      ...   \n",
       "35905  102952.0       1.0      2.0      2.0     b'S'      2.0     b'S'   \n",
       "35906  102953.0       1.0      2.0      2.0     b'S'      2.0     b'S'   \n",
       "35907  102954.0       1.0      2.0      2.0     b'S'      2.0     b'S'   \n",
       "35908  102955.0       1.0      4.0      2.0     b'S'      2.0     b'S'   \n",
       "35909  102956.0       1.0      4.0      4.0     b'E'      2.0     b'S'   \n",
       "\n",
       "       OHX04TC OHX04CTC  OHX05TC  ... OHX27CTC  OHX28TC OHX28CTC  OHX29TC  \\\n",
       "1          2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "2          1.0     b'D'      1.0  ...     b'D'      1.0     b'D'      1.0   \n",
       "3          2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "4          2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "5          2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "...        ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "35905      2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "35906      2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "35907      2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "35908      2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "35909      2.0     b'S'      2.0  ...     b'S'      2.0     b'S'      2.0   \n",
       "\n",
       "      OHX29CTC  OHX30TC OHX30CTC  OHX31TC OHX31CTC     cohort  \n",
       "1         b'S'      2.0     b'Z'      2.0     b'S'  2011-2012  \n",
       "2         b'D'      4.0     b'U'      4.0     b'U'  2011-2012  \n",
       "3         b'S'      2.0     b'Y'      2.0     b'S'  2011-2012  \n",
       "4         b'S'      2.0     b'Z'      2.0     b'Z'  2011-2012  \n",
       "5         b'S'      2.0     b'S'      2.0     b'S'  2011-2012  \n",
       "...        ...      ...      ...      ...      ...        ...  \n",
       "35905     b'S'      2.0     b'S'      2.0     b'S'  2017-2018  \n",
       "35906     b'S'      2.0     b'S'      2.0     b'Z'  2017-2018  \n",
       "35907     b'F'      2.0     b'S'      2.0     b'S'  2017-2018  \n",
       "35908     b'S'      2.0     b'S'      2.0     b'Z'  2017-2018  \n",
       "35909     b'S'      2.0     b'S'      4.0     b'E'  2017-2018  \n",
       "\n",
       "[35909 rows x 62 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same as in (a), I spend a lot of lines to make the indexes in \n",
    "# the final data frame right.\n",
    "\n",
    "col = ['SEQN', 'OHDDESTS']\n",
    "for i in range(1, 10):\n",
    "    col.append('OHX0'+str(i)+'TC')\n",
    "    col.append('OHX0'+str(i)+'CTC')\n",
    "for i in range(10, 32):\n",
    "    col.append('OHX'+str(i)+'TC')\n",
    "    col.append('OHX'+str(i)+'CTC')\n",
    "col.remove(\"OHX16CTC\")\n",
    "col.remove(\"OHX17CTC\")\n",
    "col.remove(\"OHX01CTC\")\n",
    "    \n",
    "    \n",
    "    \n",
    "df1 = pd.read_sas('OHXDEN_G.XPT')\n",
    "df1 = df1[col]\n",
    "n_df1 = df1.shape[0]\n",
    "df1['cohort'] = ['2011-2012'] * n_df1\n",
    "\n",
    "dic_df1 = {}\n",
    "for name in df1.columns:\n",
    "    dic_df1[name] = list(df1[name])\n",
    "df1_frame = pd.DataFrame(\n",
    "    dic_df1, index = list(range(1, n_df1+1))\n",
    ")\n",
    "\n",
    "\n",
    "df2 = pd.read_sas('OHXDEN_H.XPT')\n",
    "df2 = df2[col]\n",
    "n_df2 = df2.shape[0]\n",
    "df2['cohort'] = ['2013-2014'] * n_df2\n",
    "\n",
    "dic_df2 = {}\n",
    "for name in df2.columns:\n",
    "    dic_df2[name] = list(df2[name])\n",
    "df2_frame = pd.DataFrame(\n",
    "    dic_df2, index = list(range(n_df1 + 1, n_df1 + n_df2 + 1))\n",
    ")\n",
    "\n",
    "df3 = pd.read_sas('OHXDEN_I.XPT')\n",
    "df3 = df3[col]\n",
    "n_df3 = df3.shape[0]\n",
    "df3['cohort'] = ['2015-2016'] * n_df3\n",
    "\n",
    "dic_df3 = {}\n",
    "for name in df3.columns:\n",
    "    dic_df3[name] = list(df3[name])\n",
    "df3_frame = pd.DataFrame(\n",
    "    dic_df3, index = list(range(n_df1 + n_df2 + 1, n_df1 + n_df2 + \n",
    "                                n_df3 + 1))\n",
    ")\n",
    "\n",
    "df4 = pd.read_sas('OHXDEN_J.XPT')    \n",
    "df4 = df4[col]\n",
    "n_df4 = df4.shape[0]\n",
    "df4['cohort'] = ['2017-2018'] * n_df4\n",
    "\n",
    "dic_df4 = {}\n",
    "for name in df4.columns:\n",
    "    dic_df4[name] = list(df4[name])\n",
    "df4_frame = pd.DataFrame(\n",
    "    dic_df4, index = list(range(n_df1 + n_df2 + n_df3 + 1, n_df1 + \n",
    "                                n_df2 + n_df3 + n_df4 + 1))\n",
    ")\n",
    "\n",
    "\n",
    "df_oral = pd.concat([df1_frame, df2_frame, df3_frame, df4_frame])\n",
    "df_oral.rename(columns={'SEQN':'id'}, inplace=True)\n",
    "\n",
    "\n",
    "print(df_oral.dtypes)\n",
    "df_oral.to_pickle('df_oral.pickle')\n",
    "df_oral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248acc0c",
   "metadata": {},
   "source": [
    "c. In your notebook, report the number of cases there are in the two datasets above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f0b0ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cases in the first dataset is 39156.\n",
      "The number of cases in the second dataset is 35909.\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of cases in the first dataset is \" \n",
    "      + str(df_demo.shape[0]) + '.')\n",
    "print(\"The number of cases in the second dataset is \" \n",
    "      + str(df_oral.shape[0]) + '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
